{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d28931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd07a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade Anthropic-Bibliothek...\n",
      "Anthropic (Claude) Bibliothek erfolgreich geladen.\n",
      "Alle Bibliotheken sind bereit.\n",
      "======================================================================\n",
      "\n",
      "--- Schritt 2: Reparierte Daten laden & API-Client initialisieren ---\n",
      "Datensatz geladen: ergebnisse/2.2_rfd_repaired_llm.csv (1326 Zeilen)\n",
      "STATUS: Spalten 'price'/'saving' für LLM-Analyse vorbereitet (Float/NaN-bereinigt).\n",
      "Anthropic (Claude) API-Client und Modell 'claude-sonnet-4-5-20250929' initialisiert.\n",
      "======================================================================\n",
      "\n",
      "--- Schritt 3: Prompt-Strategie und Hilfsfunktionen ---\n",
      "SYSTEM_PROMPT (Ausreißerbewertung mit erweitertem Fokus) definiert.\n",
      "Hilfsfunktionen definiert.\n",
      "======================================================================\n",
      "\n",
      "--- Schritt 4: Ausführung der Ausreißererkennung auf dem gesamten Datensatz ---\n",
      "Starte LLM-Analyse für 1326 Zeilen mit 'claude-sonnet-4-5-20250929'...\n",
      "----------------------------------------------------------------------\n",
      "  ...verarbeite Zeile 25 von 1326\n",
      "  ...verarbeite Zeile 50 von 1326\n",
      "  ...verarbeite Zeile 75 von 1326\n",
      "  ...verarbeite Zeile 100 von 1326\n",
      "  ...verarbeite Zeile 125 von 1326\n",
      "  ...verarbeite Zeile 150 von 1326\n",
      "  ...verarbeite Zeile 175 von 1326\n",
      "  ...verarbeite Zeile 200 von 1326\n",
      "  ...verarbeite Zeile 225 von 1326\n",
      "  ...verarbeite Zeile 250 von 1326\n",
      "  ...verarbeite Zeile 275 von 1326\n",
      "  ...verarbeite Zeile 300 von 1326\n",
      "  ...verarbeite Zeile 325 von 1326\n",
      "  ...verarbeite Zeile 350 von 1326\n",
      "  ...verarbeite Zeile 375 von 1326\n",
      "  ...verarbeite Zeile 400 von 1326\n",
      "  ...verarbeite Zeile 425 von 1326\n",
      "  ...verarbeite Zeile 450 von 1326\n",
      "  ...verarbeite Zeile 475 von 1326\n",
      "  ...verarbeite Zeile 500 von 1326\n",
      "  ...verarbeite Zeile 525 von 1326\n",
      "  ...verarbeite Zeile 550 von 1326\n",
      "  ...verarbeite Zeile 575 von 1326\n",
      "  ...verarbeite Zeile 600 von 1326\n",
      "  ...verarbeite Zeile 625 von 1326\n",
      "  ...verarbeite Zeile 650 von 1326\n",
      "  ...verarbeite Zeile 675 von 1326\n",
      "  ...verarbeite Zeile 700 von 1326\n",
      "  ...verarbeite Zeile 725 von 1326\n",
      "  ...verarbeite Zeile 750 von 1326\n",
      "  ...verarbeite Zeile 775 von 1326\n",
      "  ...verarbeite Zeile 800 von 1326\n",
      "  ...verarbeite Zeile 825 von 1326\n",
      "  ...verarbeite Zeile 850 von 1326\n",
      "  ...verarbeite Zeile 875 von 1326\n",
      "  ...verarbeite Zeile 900 von 1326\n",
      "  ...verarbeite Zeile 925 von 1326\n",
      "  ...verarbeite Zeile 950 von 1326\n",
      "  ...verarbeite Zeile 975 von 1326\n",
      "  ...verarbeite Zeile 1000 von 1326\n",
      "  ...verarbeite Zeile 1025 von 1326\n",
      "  ...verarbeite Zeile 1050 von 1326\n",
      "  ...verarbeite Zeile 1075 von 1326\n",
      "  ...verarbeite Zeile 1100 von 1326\n",
      "  ...verarbeite Zeile 1125 von 1326\n",
      "  ...verarbeite Zeile 1150 von 1326\n",
      "  ...verarbeite Zeile 1175 von 1326\n",
      "  ...verarbeite Zeile 1200 von 1326\n",
      "  ...verarbeite Zeile 1225 von 1326\n",
      "  ...verarbeite Zeile 1250 von 1326\n",
      "  ...verarbeite Zeile 1275 von 1326\n",
      "  ...verarbeite Zeile 1300 von 1326\n",
      "  ...verarbeite Zeile 1325 von 1326\n",
      "----------------------------------------------------------------------\n",
      "LLM-Gesamtlaufzeit (Experiment 3.5, LLM-Basis): 7104.19 Sekunden (≈ 118.40 Minuten).\n",
      "Durchschnittliche Laufzeit pro Zeile: 5.36 Sekunden.\n",
      "----------------------------------------------------------------------\n",
      "LLM-Verarbeitung abgeschlossen.\n",
      "\n",
      "--- Schritt 5: Ergebnisse konsolidieren und speichern ---\n",
      "Quantitative Indizes gespeichert in: 'ergebnisse/3.5_llm_ausreisser_indizes.csv'\n",
      "Komplette Ergebnisse (inkl. Begründungen) gespeichert in: 'ergebnisse/3.5_llm_komplette_ergebnisse.csv'\n",
      "\n",
      "--- SCHRITT 6: Zusammenfassung EXPERIMENT 3.5 (LLM-Detektion - LLM-Basis) ---\n",
      "Methode:           Moderne KI: LLM (Claude 4.5 Sonnet)\n",
      "Basisdaten:        ergebnisse/2.2_rfd_repaired_llm.csv\n",
      "Zielspalten:       ['replies', 'views', 'votes', 'price', 'saving'] (5 Spalten)\n",
      "ERGEBNIS (COUNT):  304 einzigartige Ausreißerzeilen identifiziert.\n",
      "Übersprungene Zeilen: 0\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# MASTERARBEIT - SKRIPT 13:\n",
    "# EXPERIMENT 3.5 (Forschungsfrage 3) - AUSREISSERERKENNUNG (LLM-Basis)\n",
    "################################################################################\n",
    "#\n",
    "# ZWECK DIESES SKRIPTS (Methodik gemäß Forschungsfrage 3):\n",
    "#\n",
    "# 1. (Basis): Misst den Einfluss der LLM-Inkonsistenzbehebung (FF2.2) auf die \n",
    "#    Ausreißererkennung (Erweiterung auf 'price'/'saving').\n",
    "#\n",
    "# 2. (Datenbasis): Lädt den vom LLM reparierten Datensatz (2.2_rfd_repaired_llm.csv).\n",
    "#\n",
    "# 3. (Zielspalten/Kontext): Erweitert die Ausreißerbewertung auf \n",
    "#    die reparierten Spalten ('price', 'saving').\n",
    "#\n",
    "# 4. (Methodik): Wendet den semantischen LLM-Ansatz (FF1) auf der bereinigten Basis an.\n",
    "#\n",
    "# 5. (Detektion & Begründung): Das LLM wird angewiesen, die binäre Entscheidung \n",
    "#    und die Begründung (für Forschungsfrage 4) zurückzugeben.\n",
    "#\n",
    "# 6. (Speichern): Speichert die Ergebnisse (Indizes und Begründungen).\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# Schritt 1: Notwendige Bibliotheken importieren\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import json\n",
    "import time\n",
    "from anthropic import Anthropic, RateLimitError, APIError\n",
    "\n",
    "# --- GLOBALE KONSTANTEN FÜR DIESES EXPERIMENT ---\n",
    "# Wir replizieren FF1, aber die Basis ist jetzt die reparierte Datei.\n",
    "DATEIPFAD_LLM_REPAIRED = 'ergebnisse/2.2_rfd_repaired_llm.csv'\n",
    "DATEIPFAD_OUTPUT_INDIZES = 'ergebnisse/3.5_llm_ausreisser_indizes.csv'\n",
    "DATEIPFAD_OUTPUT_KOMPLETT = 'ergebnisse/3.5_llm_komplette_ergebnisse.csv'\n",
    "\n",
    "# ZIELSPALTEN: FF1-Spalten + die durch FF2 reparierten Spalten\n",
    "zielspalten = ['replies', 'views', 'votes', 'price', 'saving']\n",
    "\n",
    "# --- TECHNISCHE KONSTANTEN ---\n",
    "MODELL_NAME = \"claude-sonnet-4-5-20250929\"\n",
    "MAX_TOKENS = 500  # Weniger Tokens als bei Reparatur, da keine ganze Zeile zurückkommt\n",
    "\n",
    "# Technische Warnungen ignorieren\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "print(\"Lade Anthropic-Bibliothek...\")\n",
    "try:\n",
    "    print(\"Anthropic (Claude) Bibliothek erfolgreich geladen.\")\n",
    "except Exception:\n",
    "    sys.exit(\"Skript gestoppt.\")\n",
    "\n",
    "print(\"Alle Bibliotheken sind bereit.\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# --- SCHRITT 2: DATEN LADEN, API-CLIENT & DATENVORBEREITUNG ---\n",
    "print(\"\\n--- Schritt 2: Reparierte Daten laden & API-Client initialisieren ---\")\n",
    "\n",
    "# 1. Laden der LLM-reparierten Daten\n",
    "try:\n",
    "    # LLM-Daten laden (Index wird mitgeladen)\n",
    "    df_llm = pd.read_csv(DATEIPFAD_LLM_REPAIRED, index_col='original_index')\n",
    "    df_llm = df_llm.reset_index(drop=False)  # Index als Spalte 'original_index' beibehalten\n",
    "    print(f\"Datensatz geladen: {DATEIPFAD_LLM_REPAIRED} ({df_llm.shape[0]} Zeilen)\")\n",
    "except FileNotFoundError:\n",
    "    print(\"FEHLER: Reparierte Basisdatei nicht gefunden.\")\n",
    "    sys.exit(\"Skript gestoppt.\")\n",
    "\n",
    "# 2. Typkonvertierung (ZWINGEND für die Analyse)\n",
    "# Der Reparaturschritt von FF2 macht die Konvertierung möglich.\n",
    "try:\n",
    "    df_llm['price'] = pd.to_numeric(df_llm['price'], errors='coerce')\n",
    "    df_llm['saving'] = pd.to_numeric(df_llm['saving'], errors='coerce')\n",
    "    df_llm[['price', 'saving']] = df_llm[['price', 'saving']].fillna(0)  # NaN mit 0 füllen\n",
    "    print(\"STATUS: Spalten 'price'/'saving' für LLM-Analyse vorbereitet (Float/NaN-bereinigt).\")\n",
    "except Exception:\n",
    "    print(\"FEHLER: Konnte 'price'/'saving' nicht konvertieren. Daten sind nicht numerisch.\")\n",
    "    sys.exit(\"Skript gestoppt.\")\n",
    "\n",
    "# 3. Initialisierung des API-Clients\n",
    "try:\n",
    "    client = Anthropic()\n",
    "    print(f\"Anthropic (Claude) API-Client und Modell '{MODELL_NAME}' initialisiert.\")\n",
    "except Exception:\n",
    "    print(\"FEHLER: Der Anthropic API-Client konnte nicht initialisiert werden.\")\n",
    "    sys.exit(\"Skript gestoppt.\")\n",
    "\n",
    "# 4. Datenvorbereitung (NaN zu Leerstring)\n",
    "# Da das LLM-Reparaturskript (Skript 08) bereits alle numerischen NaNs in 0 umgewandelt hat,\n",
    "# müssen wir hier nur die Metadaten-NaNs (Textspalten) zu Leerstrings konvertieren.\n",
    "df_llm_input = df_llm.copy().fillna('')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# SCHRITT 3: Definition der Prompt-Strategie und Hilfsfunktionen\n",
    "print(\"\\n--- Schritt 3: Prompt-Strategie und Hilfsfunktionen ---\")\n",
    "\n",
    "# --- 3.1: SYSTEM_PROMPT (FF1-Logik: Ausreißer suchen + Begründung) ---\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Du bist ein Modell zur kontextuellen Ausreißererkennung in bereinigten, tabellarischen Daten.\n",
    "Deine Aufgabe ist es, einzelne Datenzeilen zu bewerten.\n",
    "\n",
    "DATENSATZKONTEXT:\n",
    "Die Daten stammen aus einem Online-Deal-Forum und wurden bereits bereinigt (Datentypen sind korrigiert).\n",
    "Wichtige Spalten sind u.a.:\n",
    "- 'title': Titel des Deals/Posts\n",
    "- 'votes': Summe aus Up- und Downvotes\n",
    "- 'replies': Anzahl der Antworten\n",
    "- 'views': Anzahl der Aufrufe\n",
    "- 'price': Angebotspreis (numerisch bereinigt)\n",
    "- 'saving': Ersparnis (numerisch bereinigt)\n",
    "\n",
    "ZIELSPALTEN (ZU BEWERTEN):\n",
    "Bewerte ausschließlich die Werte in den Spalten:\n",
    "['replies', 'views', 'votes', 'price', 'saving'].\n",
    "\n",
    "KONTEXT:\n",
    "Nutze alle anderen Spalten der Zeile (z.B. 'title', 'source', 'thread_category')\n",
    "als Kontextsignale. Sie geben Hinweise auf Produktart, Marktwert, Beliebtheit und Deal-Charakter.\n",
    "\n",
    "GRUNDIDEE:\n",
    "Beurteile, ob die numerischen Werte in den Zielspalten im Verhältnis zum Kontext\n",
    "ungewöhnlich (Ausreißer) oder erwartbar (Normal) sind.\n",
    "\n",
    "- Ein Wert ist ein Ausreißer, wenn er für die Art des Produkts oder Deals im 'title'\n",
    "  extrem untypisch erscheint (z.B. extrem hoher Preis für ein Billigprodukt,\n",
    "  oder extrem hohe Views für ein Nischenthema).\n",
    "- Beachte: Die Daten sind technisch bereinigt. Bewerte jetzt die inhaltliche\n",
    "  Auffälligkeit der Zahlenwerte im Kontext.\n",
    "\n",
    "ORIENTIERUNG:\n",
    "- 'price' & 'saving': Ist der Preis für das im Titel genannte Produkt realistisch?\n",
    "  (z.B. Laptop für 5€ -> Ausreißer? Oder Laptop für 5000€ -> Ausreißer?)\n",
    "- 'engagement' ('views', 'replies', 'votes'): Passt die Aktivität zur Attraktivität des Deals?\n",
    "- Negative 'votes' sind weiterhin möglich und kein alleiniger Grund für einen Ausreißer.\n",
    "\n",
    "AUSGABEFORMAT (VERPFLICHTEND):\n",
    "Gib deine Antwort NUR als gültiges JSON-Objekt zurück, ohne zusätzlichen Text.\n",
    "\n",
    "Das JSON-Format muss exakt wie folgt aussehen:\n",
    "{\n",
    "  \"is_outlier\": true/false,\n",
    "  \"begruendung\": \"Kurze (1–2 Sätze) Erklärung, warum die Werte im Kontext als unauffällig (false) oder deutlich ungewöhnlich (true) eingestuft werden.\",\n",
    "  \"zielspalten_bewertet\": [\"replies\", \"views\", \"votes\", \"price\", \"saving\"]\n",
    "}\n",
    "\"\"\"\n",
    "print(\"SYSTEM_PROMPT (Ausreißerbewertung mit erweitertem Fokus) definiert.\")\n",
    "\n",
    "\n",
    "# --- 3.2: Definition der USER_PROMPT Funktion ---\n",
    "def erstelle_user_prompt(daten_zeile):\n",
    "    \"\"\"Konvertiert eine Pandas Series (Zeile) in einen formatierten JSON-String.\"\"\"\n",
    "    try:\n",
    "        zeilen_dict = daten_zeile.to_dict()\n",
    "        zeilen_json = json.dumps(zeilen_dict, indent=2, ensure_ascii=False)\n",
    "        user_prompt = f\"\"\"\n",
    "Hier sind die Daten für eine einzelne Zeile im JSON-Format. \n",
    "Bewerte diese Zeile gemäß den Anweisungen im SYSTEM_PROMPT.\n",
    "\n",
    "DATENZEILE:\n",
    "{zeilen_json}\n",
    "\"\"\"\n",
    "        return user_prompt\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "# --- 3.3: HILFSFUNKTION: API-AUFRUF MIT BACKOFF ---\n",
    "def rufe_claude_api_mit_backoff(system_prompt, user_prompt, model, max_retries=5):\n",
    "    \"\"\"Führt den Anthropic API-Aufruf mit Exponential Backoff durch.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.messages.create(\n",
    "                model=model,\n",
    "                max_tokens=MAX_TOKENS,\n",
    "                system=system_prompt,\n",
    "                messages=[{\"role\": \"user\", \"content\": user_prompt}],\n",
    "                temperature=0.0\n",
    "            )\n",
    "            raw_json_text = response.content[0].text.strip()\n",
    "            \n",
    "            # Robuste JSON-Extraktion\n",
    "            start = raw_json_text.find('{')\n",
    "            end = raw_json_text.rfind('}') + 1\n",
    "            \n",
    "            if start != -1 and end != -1 and end > start:\n",
    "                extracted_json = raw_json_text[start:end]\n",
    "                return json.loads(extracted_json)\n",
    "            else:\n",
    "                raise json.JSONDecodeError(\"JSON nicht extrahierbar.\", raw_json_text, 0)\n",
    "            \n",
    "        except RateLimitError:\n",
    "            delay = 2 ** attempt\n",
    "            time.sleep(delay)\n",
    "            continue\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "\n",
    "print(\"Hilfsfunktionen definiert.\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# SCHRITT 4: HAUPTVERARBEITUNGSSCHLEIFE (EXECUTION)\n",
    "print(\"\\n--- Schritt 4: Ausführung der Ausreißererkennung auf dem gesamten Datensatz ---\")\n",
    "\n",
    "ergebnis_liste = []\n",
    "fehler_indizes = []\n",
    "\n",
    "print(f\"Starte LLM-Analyse für {df_llm_input.shape[0]} Zeilen mit '{MODELL_NAME}'...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Laufzeitmessung START (Experiment 3.5, LLM-Detektion auf LLM-Basis)\n",
    "start_zeit = time.time()\n",
    "\n",
    "for index, row in df_llm_input.iterrows():\n",
    "    \n",
    "    if index % 25 == 0 and index > 0:\n",
    "        print(f\"  ...verarbeite Zeile {index} von {df_llm_input.shape[0]}\")\n",
    "        time.sleep(1)  # Kleine Pause\n",
    "        \n",
    "    user_prompt = erstelle_user_prompt(row)\n",
    "    \n",
    "    ergebnis_dict = rufe_claude_api_mit_backoff(SYSTEM_PROMPT, user_prompt, MODELL_NAME)\n",
    "    \n",
    "    if ergebnis_dict:\n",
    "        ergebnis_dict['original_index'] = row['original_index']\n",
    "        ergebnis_liste.append(ergebnis_dict)\n",
    "    else:\n",
    "        fehler_indizes.append(index)\n",
    "        print(f\"  [FEHLER/FALLBACK] Zeile {index} übersprungen.\")\n",
    "\n",
    "# Laufzeitmessung ENDE\n",
    "end_zeit = time.time()\n",
    "laufzeit_sek = end_zeit - start_zeit\n",
    "durchschnitt_pro_zeile = laufzeit_sek / df_llm_input.shape[0]\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"LLM-Gesamtlaufzeit (Experiment 3.5, LLM-Basis): {laufzeit_sek:.2f} Sekunden \"\n",
    "      f\"(≈ {laufzeit_sek/60:.2f} Minuten).\")\n",
    "print(f\"Durchschnittliche Laufzeit pro Zeile: {durchschnitt_pro_zeile:.2f} Sekunden.\")\n",
    "print(\"-\" * 70)\n",
    "print(\"LLM-Verarbeitung abgeschlossen.\")\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# SCHRITT 5: Ergebnisse konsolidieren und speichern\n",
    "print(\"\\n--- Schritt 5: Ergebnisse konsolidieren und speichern ---\")\n",
    "\n",
    "if len(ergebnis_liste) == 0:\n",
    "    print(\"FEHLER: Keine Ergebnisse zum Speichern vorhanden.\")\n",
    "    sys.exit(\"Skript gestoppt.\")\n",
    "\n",
    "df_ergebnisse_llm = pd.DataFrame(ergebnis_liste)\n",
    "df_ergebnisse_llm = df_ergebnisse_llm.set_index('original_index').sort_index()\n",
    "\n",
    "os.makedirs('ergebnisse', exist_ok=True)\n",
    "\n",
    "# 1. Speichern der Indizes (quantitativer Vergleich)\n",
    "try:\n",
    "    df_nur_ausreisser = df_ergebnisse_llm[\n",
    "        df_ergebnisse_llm['is_outlier'] == True\n",
    "    ]\n",
    "    df_nur_ausreisser.index.to_series().to_csv(\n",
    "        DATEIPFAD_OUTPUT_INDIZES,\n",
    "        index=False,\n",
    "        header=['Ausreisser_Index']\n",
    "    )\n",
    "    anzahl_gefundener_ausreisser = len(df_nur_ausreisser)\n",
    "    print(f\"Quantitative Indizes gespeichert in: '{DATEIPFAD_OUTPUT_INDIZES}'\")\n",
    "except Exception as e:\n",
    "    print(f\"FEHLER beim Speichern der Indizes: {e}\")\n",
    "    anzahl_gefundener_ausreisser = 0\n",
    "\n",
    "\n",
    "# 2. Speichern der kompletten Ergebnisse (qualitativer Vergleich)\n",
    "try:\n",
    "    df_ergebnisse_llm.to_csv(DATEIPFAD_OUTPUT_KOMPLETT, index=True)\n",
    "    print(f\"Komplette Ergebnisse (inkl. Begründungen) gespeichert in: '{DATEIPFAD_OUTPUT_KOMPLETT}'\")\n",
    "except Exception as e:\n",
    "    print(f\"FEHLER beim Speichern der kompletten Ergebnisse: {e}\")\n",
    "\n",
    "\n",
    "# --- SCHRITT 6: Zusammenfassung (Protokoll) ---\n",
    "print(\"\\n--- SCHRITT 6: Zusammenfassung EXPERIMENT 3.5 (LLM-Detektion - LLM-Basis) ---\")\n",
    "print(\"Methode:           Moderne KI: LLM (Claude 4.5 Sonnet)\")\n",
    "print(f\"Basisdaten:        {DATEIPFAD_LLM_REPAIRED}\")\n",
    "print(f\"Zielspalten:       {zielspalten} (5 Spalten)\")\n",
    "print(f\"ERGEBNIS (COUNT):  {anzahl_gefundener_ausreisser} einzigartige Ausreißerzeilen identifiziert.\")\n",
    "print(f\"Übersprungene Zeilen: {len(fehler_indizes)}\")\n",
    "print(\"=\" * 70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TabPFN_Unsupervised",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
