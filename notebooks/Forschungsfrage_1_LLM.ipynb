{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf8b89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade notwendige Bibliotheken (Pandas, Numpy, Matplotlib, OS, sys, json)...\n",
      "Anthropic (Claude) Bibliothek erfolgreich geladen.\n",
      "Alle Bibliotheken sind bereit.\n",
      "======================================================================\n",
      "--- Schritt 2: 'Schmutzigen' Rohdatensatz laden & API-Client initialisieren ---\n",
      "Datensatz geladen: rfd_main.csv\n",
      "Dimensionen (Zeilen, Spalten): (1326, 15)\n",
      "----------------------------------------\n",
      "Anthropic (Claude) API-Client erfolgreich initialisiert.\n",
      "======================================================================\n",
      "\n",
      "--- Schritt 3: Definition der Ziel- und Kontextspalten ---\n",
      "Zielspalten (zu bewerten): ['replies', 'views', 'votes']\n",
      "Kontextspalten (zur Analyse): 10 Spalten werden an das LLM gesendet.\n",
      "\n",
      "Bereite LLM-Input-Daten vor (Konvertiere NaN zu leeren Strings)...\n",
      "Vorbereitung abgeschlossen. Datenstruktur für LLM-Input:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1326 entries, 0 to 1325\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   title            1326 non-null   object\n",
      " 1   price            1326 non-null   object\n",
      " 2   saving           1326 non-null   object\n",
      " 3   parent_category  1326 non-null   object\n",
      " 4   thread_category  1326 non-null   object\n",
      " 5   source           1326 non-null   object\n",
      " 6   author           1326 non-null   object\n",
      " 7   replies          1326 non-null   int64 \n",
      " 8   views            1326 non-null   int64 \n",
      " 9   votes            1326 non-null   int64 \n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 103.7+ KB\n",
      "======================================================================\n",
      "\n",
      "--- Schritt 4: Definition der Prompt-Strategie ---\n",
      "SYSTEM_PROMPT (Regelwerk für das LLM) wurde definiert.\n",
      "Funktion 'erstelle_user_prompt' (zur Datenformatierung) wurde definiert.\n",
      "======================================================================\n",
      "\n",
      "--- Schritt 5: Testlauf (Probelauf) mit einer einzelnen Zeile ---\n",
      "Starte Testlauf mit Zeile 0...\n",
      "Sende Anfrage an Claude API (Modell: claude-sonnet-4-5-20250929)...\n",
      "Rohe Text-Antwort vom LLM erhalten.\n",
      "\n",
      "--- ERGEBNIS DES TESTLAUFS (Geparstes JSON) ---\n",
      "Originale Zieldaten (Index 0):\n",
      "{'replies': 89, 'views': 15445, 'votes': 132}\n",
      "\n",
      "LLM-Bewertung:\n",
      "{\n",
      "  \"is_outlier\": true,\n",
      "  \"begruendung\": \"Ein einfaches Händedesinfektionsmittel für $6.99 ohne ausgewiesene Ersparnis zeigt mit 89 Antworten, 15.445 Aufrufen und 132 Votes ein extrem hohes Engagement, das für diesen unspektakulären Alltagsartikel deutlich unerwartet ist. Solche Standardprodukte ohne besonderen Deal-Charakter generieren typischerweise wesentlich weniger Interaktion.\",\n",
      "  \"zielspalten_bewertet\": [\n",
      "    \"replies\",\n",
      "    \"views\",\n",
      "    \"votes\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "STATUS: Testlauf erfolgreich. JSON-Format ist korrekt.\n",
      "======================================================================\n",
      "\n",
      "--- Schritt 6: Ausführung des Experiments auf dem gesamten Datensatz ---\n",
      "Starte die Verarbeitung von 1326 Zeilen...\n",
      "Dies wird lange dauern. Bitte haben Sie Geduld.\n",
      "----------------------------------------\n",
      "  ...verarbeite Zeile 25 von 1326\n",
      "  ...verarbeite Zeile 50 von 1326\n",
      "  ...verarbeite Zeile 75 von 1326\n",
      "  ...verarbeite Zeile 100 von 1326\n",
      "  ...verarbeite Zeile 125 von 1326\n",
      "  ...verarbeite Zeile 150 von 1326\n",
      "  ...verarbeite Zeile 175 von 1326\n",
      "  ...verarbeite Zeile 200 von 1326\n",
      "  ...verarbeite Zeile 225 von 1326\n",
      "  ...verarbeite Zeile 250 von 1326\n",
      "  ...verarbeite Zeile 275 von 1326\n",
      "  ...verarbeite Zeile 300 von 1326\n",
      "  ...verarbeite Zeile 325 von 1326\n",
      "  ...verarbeite Zeile 350 von 1326\n",
      "  ...verarbeite Zeile 375 von 1326\n",
      "  ...verarbeite Zeile 400 von 1326\n",
      "  ...verarbeite Zeile 425 von 1326\n",
      "  ...verarbeite Zeile 450 von 1326\n",
      "  ...verarbeite Zeile 475 von 1326\n",
      "  ...verarbeite Zeile 500 von 1326\n",
      "  ...verarbeite Zeile 525 von 1326\n",
      "  ...verarbeite Zeile 550 von 1326\n",
      "  ...verarbeite Zeile 575 von 1326\n",
      "  ...verarbeite Zeile 600 von 1326\n",
      "  ...verarbeite Zeile 625 von 1326\n",
      "  ...verarbeite Zeile 650 von 1326\n",
      "  ...verarbeite Zeile 675 von 1326\n",
      "  ...verarbeite Zeile 700 von 1326\n",
      "  ...verarbeite Zeile 725 von 1326\n",
      "  ...verarbeite Zeile 750 von 1326\n",
      "  ...verarbeite Zeile 775 von 1326\n",
      "  ...verarbeite Zeile 800 von 1326\n",
      "  ...verarbeite Zeile 825 von 1326\n",
      "  ...verarbeite Zeile 850 von 1326\n",
      "  ...verarbeite Zeile 875 von 1326\n",
      "  ...verarbeite Zeile 900 von 1326\n",
      "  ...verarbeite Zeile 925 von 1326\n",
      "  ...verarbeite Zeile 950 von 1326\n",
      "FEHLER (Unbekannt) bei Zeile 966: Error code: 500 - {'type': 'error', 'error': {'type': 'api_error', 'message': 'Internal server error'}, 'request_id': None}. Zeile wird übersprungen.\n",
      "  ...verarbeite Zeile 975 von 1326\n",
      "  ...verarbeite Zeile 1000 von 1326\n",
      "  ...verarbeite Zeile 1025 von 1326\n",
      "  ...verarbeite Zeile 1050 von 1326\n",
      "  ...verarbeite Zeile 1075 von 1326\n",
      "  ...verarbeite Zeile 1100 von 1326\n",
      "  ...verarbeite Zeile 1125 von 1326\n",
      "  ...verarbeite Zeile 1150 von 1326\n",
      "  ...verarbeite Zeile 1175 von 1326\n",
      "  ...verarbeite Zeile 1200 von 1326\n",
      "  ...verarbeite Zeile 1225 von 1326\n",
      "  ...verarbeite Zeile 1250 von 1326\n",
      "  ...verarbeite Zeile 1275 von 1326\n",
      "  ...verarbeite Zeile 1300 von 1326\n",
      "  ...verarbeite Zeile 1325 von 1326\n",
      "----------------------------------------\n",
      "LLM-Gesamtlaufzeit: 7364.70 Sekunden (≈ 122.75 Minuten).\n",
      "Durchschnittliche Laufzeit pro Zeile: 5.55 Sekunden.\n",
      "Verarbeitung aller Zeilen abgeschlossen.\n",
      "Erfolgreich verarbeitete Zeilen: 1325\n",
      "Fehlgeschlagene/Übersprungene Zeilen: 1\n",
      "Fehlerhafte Indizes: [966]\n",
      "----------------------------------------\n",
      "\n",
      "--- Schritt 7: Ergebnisse verarbeiten und in DataFrame umwandeln ---\n",
      "Verarbeitung abgeschlossen. Hier sind die ersten 5 LLM-Bewertungen:\n",
      "                is_outlier                                        begruendung  \\\n",
      "original_index                                                                  \n",
      "0                     True  Ein einfaches Händedesinfektionsmittel für $6....   \n",
      "1                    False  Ein 20%-Coupon für RYOBI-Werkzeuge bei Home De...   \n",
      "2                    False  Ein kostenloses Angebot für verschreibungspfli...   \n",
      "3                    False  Ein Fat-Tire-Bike für ~470$ bei Costco ist ein...   \n",
      "4                    False  Das Engagement (24 Antworten, 2981 Aufrufe, 9 ...   \n",
      "\n",
      "                   zielspalten_bewertet  \n",
      "original_index                           \n",
      "0               [replies, views, votes]  \n",
      "1               [replies, views, votes]  \n",
      "2               [replies, views, votes]  \n",
      "3               [replies, views, votes]  \n",
      "4               [replies, views, votes]  \n",
      "======================================================================\n",
      "\n",
      "--- Schritt 8: Ergebnisse speichern und Zusammenfassung ---\n",
      "Qualitative Ergebnisse (inkl. Begründungen) gespeichert in: 'ergebnisse/1.5_llm_komplette_ergebnisse.csv'\n",
      "Quantitative Indizes (nur Ausreißer) gespeichert in: 'ergebnisse/1.5_llm_ausreisser_indizes.csv'\n",
      "======================================================================\n",
      "\n",
      "--- SCHRITT 9: Zusammenfassung EXPERIMENT 1.5 (LLM) ---\n",
      "Methode:           Moderne KI: LLM (Claude 4.5 Sonnet)\n",
      "Zieldaten:         rfd_main.csv (Shape: (1326, 15))\n",
      "Zielspalten:       ['replies', 'views', 'votes']\n",
      "Kontextspalten:    10 Spalten\n",
      "Verarbeitete Zeilen: 1325 / 1326\n",
      "----------------------------------------\n",
      "ERGEBNIS (COUNT):  419 einzigartige Ausreißerzeilen identifiziert.\n",
      "======================================================================\n",
      "Die Evaluierung dieser Indizes erfolgt gemäß der quantitativen Evaluationsstrategie (Abschnitt 3.4.1); die Analyse der LLM-Begründungen gemäß der qualitativen Evaluationsstrategie (Abschnitt 3.4.2) in einem separaten Evaluierungs-Skript.\n",
      "======================================================================\n",
      "=== ENDE SKRIPT 06 ===\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# MASTERARBEIT - SKRIPT 06:\n",
    "# EXPERIMENT 1.5 (Forschungsfrage 1) - AUSREISSERERKENNUNG (LLM)\n",
    "################################################################################\n",
    "#\n",
    "# ZWECK DIESES SKRIPTS (Methodik gemäß Abschnitt 3.3.1 und 3.3.4):\n",
    "#\n",
    "# 1. (Laden): Lädt den 'schmutzigen' Rohdatensatz (rfd_main.csv).\n",
    "#\n",
    "# 2. (Zielspalten/Kontext): Die Aufgabe bleibt konsistent: \n",
    "#    Identifiziere Ausreißer in den Spalten 'replies', 'views', 'votes'.\n",
    "#\n",
    "# 3. (Methode): Wendet die fünfte Methode (zweite moderne KI-Methode) an:\n",
    "#    Ein großes Sprachmodell (LLM), namentlich Claude 4.5 Sonnet.\n",
    "#\n",
    "# 4. (Methodischer Ansatz - SEMANTISCHE ANALYSE):\n",
    "#    Im Gegensatz zu den statistischen (IQR) oder dichte-basierten (LOF) \n",
    "#    Methoden, wird das LLM angewiesen, JEDE ZEILE als GANZEN \n",
    "#    (d.h. inklusive Textspalten wie 'title' oder 'price') als KONTEXT \n",
    "#    (Kontext) zu analysieren. \n",
    "#    Basierend auf diesem semantischen Verständnis soll das LLM bewerten, \n",
    "#    ob die Werte in den Zielspalten ('replies', 'views', 'votes') \n",
    "#    innerhalb dieses Kontexts plausibel oder anomal (Ausreißer) sind.\n",
    "#\n",
    "# 5. (Detektion & Begründung): Das LLM wird angewiesen, zwei Dinge \n",
    "#    zurückzugeben:\n",
    "#    a) Eine binäre Entscheidung (Ja/Nein) für die Zielspalten.\n",
    "#    b) Eine kurze, stichpunktartige Begründung (Begründung), WARUM \n",
    "#       es diese Entscheidung getroffen hat (entscheidend für Forschungsfrage 4).\n",
    "#\n",
    "# 6. (Speichern): Speichert die Ergebnisse. Um eine vollständige Analyse \n",
    "#    (quantitativ und qualitativ) zu ermöglichen, werden gespeichert:\n",
    "#    a) Die identifizierten Ausreißer-Indizes.\n",
    "#    b) Die vom LLM generierten Begründungen (für die qualitative Analyse).\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# Schritt 1: Notwendige Bibliotheken importieren\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys \n",
    "import warnings\n",
    "import json # Wichtig für die strukturierte Ein- und Ausgabe des LLM\n",
    "import time  # Für die Messung der Laufzeit des LLM-Experiments\n",
    "\n",
    "# Importieren der Anthropic-Bibliothek für die Claude-API\n",
    "# (gemäß Abschnitt 3.5 'Implementierung' als konkrete Implementierung gewählt)\n",
    "print(\"Lade notwendige Bibliotheken (Pandas, Numpy, Matplotlib, OS, sys, json)...\")\n",
    "try:\n",
    "    from anthropic import Anthropic, RateLimitError, APIError\n",
    "    print(\"Anthropic (Claude) Bibliothek erfolgreich geladen.\")\n",
    "except ImportError as e:\n",
    "    print(f\"FEHLER: Kritische Bibliothek (Anthropic) konnte nicht geladen werden.\")\n",
    "    print(f\"Fehlermeldung: {e}\")\n",
    "    print(\"Stellen Sie sicher, dass 'pip install anthropic' ausgeführt wurde.\")\n",
    "    sys.exit(\"Skript gestoppt, da Abhängigkeiten fehlen.\")\n",
    "\n",
    "print(\"Alle Bibliotheken sind bereit.\")\n",
    "print(\"=\" * 70)\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# SCHRITT 2: Laden des 'schmutzigen' Rohdatensatzes und API-Konfiguration\n",
    "print(\"--- Schritt 2: 'Schmutzigen' Rohdatensatz laden & API-Client initialisieren ---\")\n",
    "\n",
    "# --- 2.1: Laden der Daten ---\n",
    "# Gemäß ZWECK-Schritt 1 wird der 'schmutzige' Rohdatensatz (rfd_main.csv) geladen.\n",
    "# Dies ist methodisch zwingend, um die Konsistenz mit den \n",
    "# Experimenten 1.1 (IQR), 1.2 (LOF), 1.3 (ISO) und 1.4 (TabPFN) \n",
    "# zu wahren (alle 1326 Zeilen).\n",
    "dateipfad = 'rfd_main.csv'\n",
    "df_schmutzig = pd.read_csv(dateipfad)\n",
    "\n",
    "# Die .shape-Ausgabe bestätigt die Dimensionen (1326 Zeilen).\n",
    "print(f\"Datensatz geladen: {dateipfad}\")\n",
    "print(f\"Dimensionen (Zeilen, Spalten): {df_schmutzig.shape}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- 2.2: Initialisierung des API-Clients ---\n",
    "# Wir müssen den 'Anthropic'-Client initialisieren, um Anfragen \n",
    "# an das Claude-Modell senden zu können.\n",
    "#\n",
    "# WICHTIG: Der API-Schlüssel muss in den Systemumgebungsvariablen \n",
    "# als 'ANTHROPIC_API_KEY' gespeichert sein, damit dieser Code \n",
    "# (client = Anthropic()) funktioniert.\n",
    "try:\n",
    "    client = Anthropic() \n",
    "    # (Der Client liest den API-Schlüssel automatisch aus der Umgebungsvariable)\n",
    "    print(\"Anthropic (Claude) API-Client erfolgreich initialisiert.\")\n",
    "except Exception as e:\n",
    "    print(f\"FEHLER: Der Anthropic API-Client konnte nicht initialisiert werden.\")\n",
    "    print(\"Stellen Sie sicher, dass der 'ANTHROPIC_API_KEY' in Ihren \\\n",
    "Umgebungsvariablen gesetzt ist.\")\n",
    "    print(f\"Fehlermeldung: {e}\")\n",
    "    sys.exit(\"Skript gestoppt, da API-Konfiguration fehlt.\")\n",
    "    \n",
    "print(\"=\" * 70)\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# SCHRITT 3: Definition der Ziel- und Kontextspalten\n",
    "print(\"\\n--- Schritt 3: Definition der Ziel- und Kontextspalten ---\")\n",
    "\n",
    "# --- 3.1: Zielspalten (Konsistenz der Forschungsfrage 1) ---\n",
    "#\n",
    "# Methodische Konsistenz: Um die Ergebnisse mit IQR, LOF, TabPFN, etc. \n",
    "# vergleichen zu können (Forschungsfrage 1), bleibt die Kernaufgabe \n",
    "# des Modells identisch: Finde statistische Ausreißer in DIESEN drei Spalten.\n",
    "zielspalten = ['replies', 'views', 'votes']\n",
    "print(f\"Zielspalten (zu bewerten): {zielspalten}\")\n",
    "\n",
    "# --- 3.2: Kontextspalten (Semantische Analyse) ---\n",
    "#\n",
    "# Methodischer Ansatz (gemäß ZWECK-Schritt 4):\n",
    "# Hier liegt der Hauptunterschied des LLM-Experiments. Wir geben dem LLM \n",
    "# den gesamten semantischen Kontext der Zeile, damit es eine \"intelligente\" \n",
    "# Entscheidung treffen kann.\n",
    "kontextspalten = [\n",
    "    'title', \n",
    "    'price', \n",
    "    'saving', \n",
    "    'parent_category', \n",
    "    'thread_category', \n",
    "    'source',\n",
    "    'author',\n",
    "    # Die Zielspalten müssen auch im Kontext enthalten sein:\n",
    "    'replies', \n",
    "    'views', \n",
    "    'votes'\n",
    "]\n",
    "print(f\"Kontextspalten (zur Analyse): {len(kontextspalten)} Spalten werden \\\n",
    "an das LLM gesendet.\")\n",
    "\n",
    "# --- 3.3: Finale Datenvorbereitung (Umgang mit NaN im KONTEXT) ---\n",
    "#\n",
    "# Methodische Notwendigkeit (basierend auf EDA Skript 01):\n",
    "# Die EDA (Skript 01, .describe() / .info()) hat gezeigt, dass unsere \n",
    "# ZIELspalten ('replies', 'views', 'votes') KEINE NaNs haben.\n",
    "#\n",
    "# ABER: Unsere KONTEXTspalten (z.B. 'price', 'saving', 'source') \n",
    "# enthalten HUNDERTE von NaN-Werten (siehe EDA-Analyse 'count').\n",
    "#\n",
    "# Ein 'NaN'-Wert kann von einem LLM nicht eindeutig interpretiert werden \n",
    "# (er wird oft als 'null' oder als String \"NaN\" gesendet). Dies würde als \n",
    "# störendes \"Rauschen\" im Prompt wirken.\n",
    "#\n",
    "# Methodische Entscheidung: Um dem LLM einen sauberen, neutralen Input \n",
    "# (z.B. \"price: ''\" statt \"price: null\") zu geben, konvertieren wir alle \n",
    "# 'NaN'-Werte aus den Kontextspalten in einen leeren String ('').\n",
    "print(\"\\nBereite LLM-Input-Daten vor (Konvertiere NaN zu leeren Strings)...\")\n",
    "\n",
    "df_llm_input = df_schmutzig[kontextspalten].copy()\n",
    "df_llm_input = df_llm_input.fillna('')\n",
    "\n",
    "# Bestätigen wir das Ergebnis (alle Spalten sollten 'non-null' sein)\n",
    "print(\"Vorbereitung abgeschlossen. Datenstruktur für LLM-Input:\")\n",
    "df_llm_input.info()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# SCHRITT 4: Definition der Prompt-Strategie (System & User Prompts)\n",
    "print(\"\\n--- Schritt 4: Definition der Prompt-Strategie ---\")\n",
    "\n",
    "# Methodischer Ansatz (gemäß ZWECK-Schritt 4 & 5):\n",
    "# Wir definieren eine \"Prompt-Strategie\", um das LLM anzuweisen.\n",
    "# Diese besteht aus zwei Teilen:\n",
    "#\n",
    "# 1. SYSTEM_PROMPT: Definiert die Rolle, die Aufgabe, den Kontext und \n",
    "#    das ZWINGEND erforderliche Ausgabeformat (JSON).\n",
    "# 2. USER_PROMPT (Funktion): Formatiert jede einzelne Zeile unserer\n",
    "#    Daten (df_llm_input) in einen sauberen String, den das LLM \n",
    "#    analysieren kann.\n",
    "\n",
    "# --- 4.1: Definition des SYSTEM_PROMPT ---\n",
    "#\n",
    "# Dieser Prompt ist der Kern der Methode. Er instruiert das LLM, \n",
    "# die 'zielspalten' im Lichte der 'kontextspalten' semantisch zu bewerten.\n",
    "# Wir fordern explizit eine JSON-Ausgabe, um die Ergebnisse \n",
    "# programmatisch (automatisiert) verarbeiten zu können.\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Du bist ein Modell zur kontextuellen Ausreißererkennung in tabellarischen Daten.\n",
    "Deine Aufgabe ist es, einzelne Datenzeilen zu bewerten.\n",
    "\n",
    "DATENSATZKONTEXT:\n",
    "Die Daten stammen aus einem Online-Deal-Forum. Wichtige Spalten sind u.a.:\n",
    "- 'title': Titel des Deals/Posts\n",
    "- 'votes': Summe aus Up- und Downvotes (kann positiv oder negativ sein)\n",
    "- 'source': Anbieter / Händler\n",
    "- 'replies': Anzahl der Antworten\n",
    "- 'views': Anzahl der Aufrufe\n",
    "- 'price': Angebotspreis\n",
    "- 'saving': ausgewiesene Ersparnis\n",
    "Negative 'votes'-Werte sind in diesem Kontext grundsätzlich möglich und allein deshalb\n",
    "kein Ausreißer.\n",
    "\n",
    "ZIELSPALTEN:\n",
    "Bewerte ausschließlich die Werte in den Spalten:\n",
    "['replies', 'views', 'votes'].\n",
    "\n",
    "KONTEXT:\n",
    "Nutze alle anderen Spalten der Zeile (z.B. 'title', 'price', 'source', 'thread_category', 'saving')\n",
    "als Kontextsignale. Sie geben Hinweise auf Thema, Attraktivität, Reichweite, Plattform,\n",
    "Zielgruppe und Deal-Charakter.\n",
    "\n",
    "GRUNDIDEE:\n",
    "Beurteile, ob das beobachtete Engagement in den Zielspalten im Verhältnis zum Kontext\n",
    "ungewöhnlich ist.\n",
    "\n",
    "- Wenn das Niveau von 'replies' / 'views' / 'votes' zum Kontext passt,\n",
    "  behandle den Datenpunkt als nicht auffällig.\n",
    "- Wenn das Niveau von 'replies' / 'views' / 'votes' im Kontext deutlich unerwartet wirkt\n",
    "  (z.B. extrem hoch oder extrem niedrig für diese Art Inhalt oder Angebot),\n",
    "  markiere den Datenpunkt als Ausreißer.\n",
    "\n",
    "ORIENTIERUNG (NUR ALS DENKHILFE, KEINE HARTE REGELN):\n",
    "\n",
    "- Weitreichende, wertige, stark nachgefragte oder kontroverse Themen/Deals können hohes\n",
    "  Engagement ('views', 'replies', 'votes') plausibel erklären.\n",
    "- Sehr einfache, lokale oder wenig attraktive Inhalte mit extrem hohem Engagement können\n",
    "  auffällig sein.\n",
    "- Sehr attraktive oder stark rabattierte Angebote mit nahezu keinem Engagement können\n",
    "  ebenfalls auffällig sein.\n",
    "- Ein Wert ist nicht allein deshalb ein Ausreißer, weil er groß, klein oder negativ ist\n",
    "  entscheide immer im Zusammenspiel mit dem Kontext. Insbesondere negative 'votes' können\n",
    "  ein normales Bewertungssignal sein.\n",
    "\n",
    "NUTZE DEIN WISSEN:\n",
    "Verwende dein allgemeines Weltwissen und dein Verständnis typischer Online-Interaktionen,\n",
    "um zu entscheiden, ob das Engagement für den gegebenen Kontext deutlich ungewöhnlich\n",
    "oder im erwartbaren Rahmen ist.\n",
    "\n",
    "AUSGABEFORMAT (VERPFLICHTEND):\n",
    "Gib deine Antwort NUR als gültiges JSON-Objekt zurück, ohne zusätzlichen Text.\n",
    "\n",
    "Das JSON-Format muss exakt wie folgt aussehen:\n",
    "{\n",
    "  \"is_outlier\": true/false,\n",
    "  \"begruendung\": \"Kurze (1–2 Sätze) Erklärung, warum das Engagement im gegebenen Kontext als unauffällig (false) oder deutlich ungewöhnlich (true) eingestuft wird.\",\n",
    "  \"zielspalten_bewertet\": [\"replies\", \"views\", \"votes\"]\n",
    "}\n",
    "\"\"\"\n",
    "print(\"SYSTEM_PROMPT (Regelwerk für das LLM) wurde definiert.\")\n",
    "\n",
    "# --- 4.2: Definition der USER_PROMPT Funktion ---\n",
    "#\n",
    "# Diese Funktion nimmt eine einzelne Zeile (als Pandas Series) aus \n",
    "# unserem 'df_llm_input' DataFrame, konvertiert sie in einen sauberen \n",
    "# JSON-String und bettet sie in eine Anweisung für das LLM ein.\n",
    "\n",
    "def erstelle_user_prompt(daten_zeile):\n",
    "    \"\"\"\n",
    "    Konvertiert eine Pandas Series (Zeile) in einen formatierten \n",
    "    JSON-String für den LLM-Prompt.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Konvertiere die Pandas-Zeile in ein Dictionary\n",
    "        zeilen_dict = daten_zeile.to_dict()\n",
    "        \n",
    "        # Konvertiere das Dictionary in einen formatierten JSON-String\n",
    "        # (indent=2 sorgt für bessere Lesbarkeit, falls wir es debuggen müssen)\n",
    "        zeilen_json = json.dumps(zeilen_dict, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # Erstelle den finalen Prompt\n",
    "        user_prompt = f\"\"\"\n",
    "Hier sind die Daten für eine einzelne Zeile im JSON-Format. \n",
    "Bewerte diese Zeile gemäß den Anweisungen im SYSTEM_PROMPT.\n",
    "\n",
    "DATENZEILE:\n",
    "{zeilen_json}\n",
    "\"\"\"\n",
    "        return user_prompt\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"FEHLER beim Erstellen des User-Prompts: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Funktion 'erstelle_user_prompt' (zur Datenformatierung) wurde definiert.\")\n",
    "print(\"=\" * 70)\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# SCHRITT 5: Testlauf (Probelauf) mit einer einzelnen Zeile\n",
    "print(\"\\n--- Schritt 5: Testlauf (Probelauf) mit einer einzelnen Zeile ---\")\n",
    "\n",
    "# Methodischer Ansatz:\n",
    "# Bevor wir das LLM auf alle 1326 Zeilen anwenden (was Zeit und \n",
    "# API-Kosten verursacht), führen wir einen Testlauf mit der ERSTEN \n",
    "# Zeile (Index 0) des DataFrames 'df_llm_input' durch.\n",
    "#\n",
    "# Ziel: Überprüfen, ob die in Schritt 4 definierte Prompt-Strategie \n",
    "# (System/User) funktioniert und ob die JSON-Ausgabe (unsere \n",
    "# Zwangsvorgabe) korrekt gelesen (geparst) werden kann.\n",
    "# Dies validiert den Ansatz der \"Verarbeitung einzelner Instanzen\".\n",
    "\n",
    "print(\"Starte Testlauf mit Zeile 0...\")\n",
    "\n",
    "# 1. Testzeile auswählen (Index 0)\n",
    "test_zeile = df_llm_input.iloc[0]\n",
    "\n",
    "# 2. User-Prompt für diese Zeile erstellen (mit der Funktion aus Schritt 4)\n",
    "test_user_prompt = erstelle_user_prompt(test_zeile)\n",
    "\n",
    "if test_user_prompt is None:\n",
    "    print(\"FEHLER: Der Test-User-Prompt konnte nicht erstellt werden.\")\n",
    "    sys.exit(\"Skript gestoppt.\")\n",
    "\n",
    "# 3. API-Anfrage senden (client wurde in Schritt 2 initialisiert)\n",
    "try:\n",
    "    print(\"Sende Anfrage an Claude API (Modell: claude-sonnet-4-5-20250929)...\")\n",
    "    \n",
    "    # Modell-Name (gemäß unserer Methodik, Abschnitt 3.3.1)\n",
    "    # Wichtig: Der spezifische Modellname muss exakt angegeben werden.\n",
    "    MODELL_NAME = \"claude-sonnet-4-5-20250929\" \n",
    "    \n",
    "    api_antwort = client.messages.create(\n",
    "        model=MODELL_NAME,\n",
    "        system=SYSTEM_PROMPT,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": test_user_prompt}\n",
    "        ],\n",
    "        max_tokens=500,  # Ausreichend Platz für die JSON-Antwort\n",
    "        temperature=0.0  # Sorgt für deterministische (reproduzierbare) \n",
    "                         # Ergebnisse, indem Kreativität unterbunden wird.\n",
    "    )\n",
    "    \n",
    "    # 4. Rohe Antwort extrahieren\n",
    "    # Die Antwort des LLM befindet sich im 'content[0].text'-Block\n",
    "    rohe_antwort_text = api_antwort.content[0].text\n",
    "    print(\"Rohe Text-Antwort vom LLM erhalten.\")\n",
    "\n",
    "except RateLimitError as e:\n",
    "    print(f\"FEHLER (RateLimitError): API-Ratenlimit überschritten. {e}\")\n",
    "    print(\"Bitte überprüfen Sie Ihr Anthropic API-Kontingent.\")\n",
    "    sys.exit(\"Skript gestoppt.\")\n",
    "except APIError as e:\n",
    "    print(f\"FEHLER (APIError): Ein API-Fehler ist aufgetreten. {e}\")\n",
    "    sys.exit(\"Skript gestoppt.\")\n",
    "except Exception as e:\n",
    "    print(f\"FEHLER (Unbekannt) bei der API-Anfrage: {e}\")\n",
    "    sys.exit(\"Skript gestoppt.\")\n",
    "\n",
    "# 5. JSON-Antwort parsen (lesen)\n",
    "# Wir müssen den (manchmal unsauberen) Text in ein sauberes JSON-Objekt umwandeln.\n",
    "try:\n",
    "    # Robuste Extraktion: Finde die erste '{' und die letzte '}'\n",
    "    json_start = rohe_antwort_text.find('{')\n",
    "    json_ende = rohe_antwort_text.rfind('}') + 1\n",
    "    \n",
    "    if json_start == -1 or json_ende == 0:\n",
    "        raise json.JSONDecodeError(\"Keine JSON-Struktur ('{' oder '}') gefunden.\", \n",
    "                                   rohe_antwort_text, 0)\n",
    "        \n",
    "    json_text_sauber = rohe_antwort_text[json_start:json_ende]\n",
    "    \n",
    "    # Konvertiere den sauberen Text in ein Python-Dictionary\n",
    "    ergebnis_dict = json.loads(json_text_sauber)\n",
    "    \n",
    "    print(\"\\n--- ERGEBNIS DES TESTLAUFS (Geparstes JSON) ---\")\n",
    "    \n",
    "    # Zeige die Zieldaten, die bewertet wurden:\n",
    "    print(\"Originale Zieldaten (Index 0):\")\n",
    "    print(test_zeile[zielspalten].to_dict())\n",
    "    print(\"\\nLLM-Bewertung:\")\n",
    "    \n",
    "    # Schöne Ausgabe des Dictionaries (mit Einrückung)\n",
    "    print(json.dumps(ergebnis_dict, indent=2, ensure_ascii=False))\n",
    "    \n",
    "    # 6. Validierung (Prüfung, ob die erwarteten Schlüssel vorhanden sind)\n",
    "    if 'is_outlier' not in ergebnis_dict or 'begruendung' not in ergebnis_dict:\n",
    "        print(\"\\nWARNUNG: Die JSON-Antwort enthält nicht die erwarteten \\\n",
    "Schlüssel ('is_outlier', 'begruendung'). Prompt muss evtl. angepasst werden.\")\n",
    "    else:\n",
    "        print(\"\\nSTATUS: Testlauf erfolgreich. JSON-Format ist korrekt.\")\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"FEHLER (JSONDecodeError): Die Antwort des LLM war kein gültiges JSON.\")\n",
    "    print(\"Dies passiert, wenn das LLM dem SYSTEM_PROMPT (Zwangsausgabe) \\\n",
    "nicht gehorcht hat.\")\n",
    "    print(f\"Fehlermeldung: {e}\")\n",
    "    print(f\"Empfangener Text (Roh):\\n{rohe_antwort_text}\")\n",
    "    sys.exit(\"Skript gestoppt.\")\n",
    "print(\"=\" * 70)\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# SCHRITT 6: Ausführung des Experiments auf dem gesamten Datensatz (1326 Zeilen)\n",
    "print(\"\\n--- Schritt 6: Ausführung des Experiments auf dem gesamten Datensatz ---\")\n",
    "\n",
    "# Methodischer Ansatz:\n",
    "# Nachdem der Testlauf (Schritt 5) erfolgreich war, wenden wir die \n",
    "# Prompt-Strategie nun in einer Schleife (Loop) auf alle 1326 Zeilen \n",
    "# des 'df_llm_input'-DataFrames an.\n",
    "#\n",
    "# Wir speichern die Ergebnisse (die JSON-Antworten) in einer Liste,\n",
    "# um sie anschließend in einen neuen DataFrame umzuwandeln.\n",
    "\n",
    "# WICHTIGER HINWEIS: Dieser Vorgang ist SEHR LANGSAM. \n",
    "# Er führt 1326 einzelne API-Anfragen an Claude durch. \n",
    "# Dies kann je nach API-Latenz und Ratenlimit 30-60 Minuten dauern.\n",
    "\n",
    "# Initialisierung der Listen zur Speicherung der Ergebnisse\n",
    "ergebnis_liste = []\n",
    "fehler_indizes = [] # Zum Protokollieren von Zeilen, die fehlschlagen\n",
    "\n",
    "print(f\"Starte die Verarbeitung von {len(df_llm_input)} Zeilen...\")\n",
    "print(\"Dies wird lange dauern. Bitte haben Sie Geduld.\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Startzeit für die Laufzeitmessung des gesamten LLM-Experiments\n",
    "start_zeit = time.time()\n",
    "\n",
    "# --- START DER SCHLEIFE (LOOP) ---\n",
    "# .itertuples() ist schneller als .iterrows() für Pandas-Schleifen\n",
    "for zeile in df_llm_input.itertuples():\n",
    "    \n",
    "    # Zeige einen Fortschrittsindikator alle 25 Zeilen\n",
    "    if zeile.Index % 25 == 0 and zeile.Index > 0:\n",
    "        print(f\"  ...verarbeite Zeile {zeile.Index} von {len(df_llm_input)}\")\n",
    "        # (Optional: Eine kleine Pause, um API-Ratenlimits zu schonen)\n",
    "        # time.sleep(1) \n",
    "\n",
    "    # 1. User-Prompt erstellen\n",
    "    # (Wir müssen das 'zeile'-Tupel in eine Series umwandeln, \n",
    "    # damit unsere Funktion 'erstelle_user_prompt' funktioniert)\n",
    "    zeilen_series = zeile._asdict()\n",
    "    # Entferne den 'Index', da er nicht Teil der Kontextspalten ist\n",
    "    zeilen_series.pop('Index', None) \n",
    "    \n",
    "    # Konvertiere zurück zu einer Pandas Series (wie in Schritt 5 erwartet)\n",
    "    zeilen_series_pd = pd.Series(zeilen_series)\n",
    "    \n",
    "    user_prompt = erstelle_user_prompt(zeilen_series_pd)\n",
    "    \n",
    "    if user_prompt is None:\n",
    "        print(f\"FEHLER (Zeile {zeile.Index}): User-Prompt konnte nicht erstellt werden. \\\n",
    "Zeile wird übersprungen.\")\n",
    "        fehler_indizes.append(zeile.Index)\n",
    "        continue # Nächste Zeile\n",
    "\n",
    "    # 2. API-Anfrage senden\n",
    "    try:\n",
    "        api_antwort = client.messages.create(\n",
    "            model=MODELL_NAME, # (Definiert in Schritt 5)\n",
    "            system=SYSTEM_PROMPT,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            max_tokens=500,\n",
    "            temperature=0.0\n",
    "        )\n",
    "        \n",
    "        rohe_antwort_text = api_antwort.content[0].text\n",
    "        \n",
    "        # 3. JSON-Antwort parsen (wie in Schritt 5)\n",
    "        json_start = rohe_antwort_text.find('{')\n",
    "        json_ende = rohe_antwort_text.rfind('}') + 1\n",
    "        json_text_sauber = rohe_antwort_text[json_start:json_ende]\n",
    "        ergebnis_dict = json.loads(json_text_sauber)\n",
    "        \n",
    "        # 4. Ergebnisse speichern\n",
    "        # Füge den originalen Index zur Nachverfolgung hinzu\n",
    "        ergebnis_dict['original_index'] = zeile.Index\n",
    "        ergebnis_liste.append(ergebnis_dict)\n",
    "\n",
    "    except RateLimitError as e:\n",
    "        print(f\"FEHLER (RateLimitError) bei Zeile {zeile.Index}: {e}\")\n",
    "        print(\"Pausiere für 30 Sekunden und versuche es erneut...\")\n",
    "        time.sleep(30)\n",
    "        # (Hier könnte man einen 'retry'-Mechanismus einbauen, \n",
    "        # aber zur Vereinfachung überspringen wir die Zeile)\n",
    "        fehler_indizes.append(zeile.Index)\n",
    "        continue\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"FEHLER (JSONDecodeError) bei Zeile {zeile.Index}: LLM gab kein \\\n",
    "gültiges JSON zurück. Zeile wird übersprungen.\")\n",
    "        print(f\"Empfangener Text (Roh): {rohe_antwort_text[:100]}...\") # Zeige nur die ersten 100 Zeichen\n",
    "        fehler_indizes.append(zeile.Index)\n",
    "        continue\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"FEHLER (Unbekannt) bei Zeile {zeile.Index}: {e}. \\\n",
    "Zeile wird übersprungen.\")\n",
    "        fehler_indizes.append(zeile.Index)\n",
    "        continue\n",
    "\n",
    "# --- ENDE DER SCHLEIFE ---\n",
    "\n",
    "end_zeit = time.time()\n",
    "laufzeit_sek = end_zeit - start_zeit\n",
    "durchschnitt_pro_zeile = laufzeit_sek / len(df_llm_input)\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"LLM-Gesamtlaufzeit: {laufzeit_sek:.2f} Sekunden \"\n",
    "      f\"(≈ {laufzeit_sek/60:.2f} Minuten).\")\n",
    "print(f\"Durchschnittliche Laufzeit pro Zeile: {durchschnitt_pro_zeile:.2f} Sekunden.\")\n",
    "\n",
    "print(\"Verarbeitung aller Zeilen abgeschlossen.\")\n",
    "print(f\"Erfolgreich verarbeitete Zeilen: {len(ergebnis_liste)}\")\n",
    "print(f\"Fehlgeschlagene/Übersprungene Zeilen: {len(fehler_indizes)}\")\n",
    "if len(fehler_indizes) > 0:\n",
    "    print(f\"Fehlerhafte Indizes: {fehler_indizes}\")\n",
    "print(\"-\" * 40)\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# SCHRITT 7: Ergebnisse verarbeiten und in DataFrame umwandeln\n",
    "print(\"\\n--- Schritt 7: Ergebnisse verarbeiten und in DataFrame umwandeln ---\")\n",
    "\n",
    "# Die 'ergebnis_liste' (aus der vorherigen Zelle, Schritt 6) \n",
    "# ist noch im Arbeitsspeicher vorhanden.\n",
    "\n",
    "if len(ergebnis_liste) == 0:\n",
    "    print(\"FEHLER: Keine Ergebnisse zum Verarbeiten vorhanden. \\\n",
    "Möglicherweise ist die vorherige Zelle (Schritt 6) fehlgeschlagen.\")\n",
    "    sys.exit(\"Skript gestoppt.\")\n",
    "\n",
    "# Konvertiere die Liste von Dictionaries (JSON-Antworten) in einen Pandas DataFrame\n",
    "df_ergebnisse_llm = pd.DataFrame(ergebnis_liste)\n",
    "\n",
    "# Setze den 'original_index' als Hauptindex des neuen DataFrames,\n",
    "# damit wir die Ergebnisse leicht den Originaldaten zuordnen können.\n",
    "df_ergebnisse_llm = df_ergebnisse_llm.set_index('original_index')\n",
    "\n",
    "# Zeige die ersten 5 Ergebnisse (Entscheidungen + Begründungen)\n",
    "print(\"Verarbeitung abgeschlossen. Hier sind die ersten 5 LLM-Bewertungen:\")\n",
    "print(df_ergebnisse_llm.head())\n",
    "print(\"=\" * 70)\n",
    "\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# SCHRITT 8: Ergebnisse speichern und Zusammenfassung\n",
    "print(\"\\n--- Schritt 8: Ergebnisse speichern und Zusammenfassung ---\")\n",
    "\n",
    "os.makedirs('ergebnisse', exist_ok=True)\n",
    "\n",
    "# Methodischer Ansatz (gemäß ZWECK-Schritt 6):\n",
    "# Wir speichern ZWEI Dateien, um die quantitative UND qualitative \n",
    "# Analyse (Forschungsfrage 4) zu ermöglichen.\n",
    "\n",
    "# 1. Definieren der Dateipfade\n",
    "ergebnis_pfad_komplett = 'ergebnisse/1.5_llm_komplette_ergebnisse.csv'\n",
    "ergebnis_pfad_indizes = 'ergebnisse/1.5_llm_ausreisser_indizes.csv'\n",
    "\n",
    "# 2. Speichern der KOMPLETTEN Ergebnisse (inkl. Begründungen)\n",
    "#    Dies ist unsere qualitative Datengrundlage für Forschungsfrage 4.\n",
    "try:\n",
    "    df_ergebnisse_llm.to_csv(ergebnis_pfad_komplett, index=True)\n",
    "    print(f\"Qualitative Ergebnisse (inkl. Begründungen) gespeichert in: \\\n",
    "'{ergebnis_pfad_komplett}'\")\n",
    "except Exception as e:\n",
    "    print(f\"FEHLER beim Speichern der kompletten Ergebnisse: {e}\")\n",
    "\n",
    "\n",
    "# 3. Speichern der INDIZES (für den quantitativen Vergleich)\n",
    "#    Wir filtern nur die Zeilen, die das LLM als 'true' (Ausreißer) \n",
    "#    markiert hat, um eine Indexliste zu erhalten, die mit \n",
    "#    IQR, LOF etc. vergleichbar ist.\n",
    "try:\n",
    "    # Filtere den DataFrame, wo 'is_outlier' == True ist\n",
    "    df_nur_ausreisser = df_ergebnisse_llm[\n",
    "        df_ergebnisse_llm['is_outlier'] == True\n",
    "    ]\n",
    "    \n",
    "    # Speichere nur den Index dieses gefilterten DataFrames\n",
    "    df_nur_ausreisser.index.to_series().to_csv(\n",
    "        ergebnis_pfad_indizes, \n",
    "        index=False, \n",
    "        header=['Ausreisser_Index']\n",
    "    )\n",
    "    print(f\"Quantitative Indizes (nur Ausreißer) gespeichert in: \\\n",
    "'{ergebnis_pfad_indizes}'\")\n",
    "    \n",
    "    # Zähle das Ergebnis für die Zusammenfassung\n",
    "    anzahl_gefundener_ausreisser = len(df_nur_ausreisser)\n",
    "\n",
    "except KeyError:\n",
    "    print(\"FEHLER: Spalte 'is_outlier' nicht in den LLM-Ergebnissen gefunden. \\\n",
    "Überprüfen Sie den SYSTEM_PROMPT.\")\n",
    "    anzahl_gefundener_ausreisser = 0\n",
    "except Exception as e:\n",
    "    print(f\"FEHLER beim Speichern der Indizes: {e}\")\n",
    "    anzahl_gefundener_ausreisser = -1 # Fehlercode\n",
    "\n",
    "print(\"=\" * 70)\n",
    "#\n",
    "################################################################################\n",
    "\n",
    "# SCHRITT 9: Zusammenfassung (Protokoll)\n",
    "print(\"\\n--- SCHRITT 9: Zusammenfassung EXPERIMENT 1.5 (LLM) ---\")\n",
    "print(f\"Methode:           Moderne KI: LLM (Claude 4.5 Sonnet)\")\n",
    "print(f\"Zieldaten:         {dateipfad} (Shape: {df_schmutzig.shape})\")\n",
    "print(f\"Zielspalten:       {zielspalten}\")\n",
    "print(f\"Kontextspalten:    {len(kontextspalten)} Spalten\")\n",
    "print(f\"Verarbeitete Zeilen: {len(ergebnis_liste)} / {len(df_llm_input)}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"ERGEBNIS (COUNT):  {anzahl_gefundener_ausreisser} einzigartige \\\n",
    "Ausreißerzeilen identifiziert.\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Die Evaluierung dieser Indizes erfolgt gemäß der quantitativen \"\n",
    "      \"Evaluationsstrategie (Abschnitt 3.4.1); die Analyse der LLM-Begründungen \"\n",
    "      \"gemäß der qualitativen Evaluationsstrategie (Abschnitt 3.4.2) \"\n",
    "      \"in einem separaten Evaluierungs-Skript.\")\n",
    "print(\"=\" * 70)\n",
    "print(\"=== ENDE SKRIPT 06 ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TabPFN_Unsupervised",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
